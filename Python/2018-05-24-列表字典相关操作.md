## 字典列表中筛选数据

**列表**中：
使用filter函数

	from random import randint
	data = [randint(-10, 10) for _ in range(10)]
	list(filter(lambda x: x > 0, data))

使用列表解析：

	[x for x in data if x > 0]
	
**字典**中：

	d = {x: randint(60, 100) for x in range(1, 21)}
	{k : v for k, v in d.items() if v > 90}

## 为元组的每个元素命名

	>>>from collections import namedtuple
	>>>Student = namedtuple('Student', ['name', 'sex'])
	>>>student = Student('yixuan',  'male')
	>>>student
	Student(name='yixuan', sex='male')
	>>>student.name   # 访问元组属性
	'yixuan'
	# 可以不用关键词赋值
	>>>test1 = test('yixuan', 'male')
	>>>test1
	Student(name='yixuan', sex='male')

## 统计序列中元素出现的频率

	>>>data = [randint(1, 21) for _ in range(20)]
	>>>data
	[6, 16, 20, 2, 8, 14, 20, 16, 17, 9, 20, 5, 19, 4, 18, 3, 9, 3, 14, 20]
	>>>c = dict.fromkeys(data, 0)
	>>>c
	{2: 0,
	 3: 0,
	 4: 0,
	 5: 0,
	 6: 0,
	 8: 0,
	 9: 0,
	 14: 0,
	 16: 0,
	 17: 0,
	 18: 0,
	 19: 0,
	 20: 0}
	 >>> from collections import Counter
	 >>>c2 = Counter(data)  # 对data中的元素统计生成字典
	 Counter({2: 1,
			 3: 2,
			 4: 1,
			 5: 1,
			 6: 1,
			 8: 1,
			 9: 2,
			 14: 2,
			 16: 2,
			 17: 1,
			 18: 1,
			 19: 1,
			 20: 4})
	>>>isinstance(c2, dict)   # 仍然是dict的子类
	True
	>>>c2.most_common(3)   # 统计出现频率最高的项
	[(20, 4), (3, 2), (9, 2)]
	
同样可以利用这个方法统计文章中的单词数：

	>>>re.split('\w+', str)   # 利用正则表达式来分词
	
## 通过字典的值对字典进行排序的方法

	>>>d = {x: randint(60, 100) for x in 'xyzabc'}
	>>>d
	{'a': 64, 'b': 73, 'c': 97, 'x': 80, 'y': 64, 'z': 90}
	>>>sorted(zip(d.values(), d.keys()))   # 通过zip的方式
	[(64, 'a'), (64, 'y'), (73, 'b'), (80, 'x'), (90, 'z'), (97, 'c')]
	>>>sorted(d.items(), key=lambda x: x[1])   # 第二种方式
	[('y', 64), ('a', 64), ('b', 73), ('x', 80), ('z', 90), ('c', 97)]
	
## 保持字典有序

	>>>from collections import OrderedDict
	>>>d = OrderedCounter(sorted(input()))
	aabbbccde
	>>>for t in d:
			print(t)
	a
	b
	c
	d
	e

`OrderedDict`是按照字典的输入顺序来保存的。
